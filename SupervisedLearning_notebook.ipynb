{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1: \n",
    "Download and prepare the data while explaining the procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing  the required library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe size: (10000, 14)\n",
      "\n",
      "Examining the first 10 rows of data in the dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examining 10 random rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>7563</td>\n",
       "      <td>15782089</td>\n",
       "      <td>Mullen</td>\n",
       "      <td>685</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58458.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>1204</td>\n",
       "      <td>15569451</td>\n",
       "      <td>Miller</td>\n",
       "      <td>463</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101257.16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118113.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>9322</td>\n",
       "      <td>15686099</td>\n",
       "      <td>Ruse</td>\n",
       "      <td>563</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82182.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>106826.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8875</th>\n",
       "      <td>8876</td>\n",
       "      <td>15768120</td>\n",
       "      <td>Brown</td>\n",
       "      <td>702</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>9.0</td>\n",
       "      <td>90560.48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174268.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>7022</td>\n",
       "      <td>15694530</td>\n",
       "      <td>Porter</td>\n",
       "      <td>672</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167268.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>169469.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>622</td>\n",
       "      <td>15603134</td>\n",
       "      <td>Pai</td>\n",
       "      <td>656</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>167878.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151887.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>9116</td>\n",
       "      <td>15692977</td>\n",
       "      <td>Ikenna</td>\n",
       "      <td>612</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130700.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77592.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>7503</td>\n",
       "      <td>15697844</td>\n",
       "      <td>Whitehouse</td>\n",
       "      <td>721</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136119.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8385</th>\n",
       "      <td>8386</td>\n",
       "      <td>15649297</td>\n",
       "      <td>T'ang</td>\n",
       "      <td>605</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111065.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125660.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>4772</td>\n",
       "      <td>15716619</td>\n",
       "      <td>Chiebuka</td>\n",
       "      <td>580</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74974.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12099.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId     Surname  CreditScore Geography  Gender  Age  \\\n",
       "7562       7563    15782089      Mullen          685    France    Male   33   \n",
       "1203       1204    15569451      Miller          463    France    Male   35   \n",
       "9321       9322    15686099        Ruse          563     Spain    Male   61   \n",
       "8875       8876    15768120       Brown          702   Germany    Male   36   \n",
       "7021       7022    15694530      Porter          672    France    Male   28   \n",
       "621         622    15603134         Pai          656     Spain  Female   40   \n",
       "9115       9116    15692977      Ikenna          612   Germany  Female   36   \n",
       "7502       7503    15697844  Whitehouse          721     Spain  Female   32   \n",
       "8385       8386    15649297       T'ang          605    France  Female   62   \n",
       "4771       4772    15716619    Chiebuka          580   Germany  Female   36   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "7562     6.0       0.00              1          1               0   \n",
       "1203     NaN  101257.16              1          1               1   \n",
       "9321     1.0   82182.10              1          1               0   \n",
       "8875     9.0   90560.48              2          1               0   \n",
       "7021     NaN  167268.98              1          1               1   \n",
       "621     10.0  167878.50              1          0               1   \n",
       "9115     NaN  130700.92              2          0               0   \n",
       "7502    10.0       0.00              1          1               0   \n",
       "8385     4.0  111065.93              2          0               1   \n",
       "4771     3.0   74974.89              1          1               1   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "7562         58458.26       0  \n",
       "1203        118113.64       0  \n",
       "9321        106826.92       1  \n",
       "8875        174268.87       0  \n",
       "7021        169469.30       0  \n",
       "621         151887.16       0  \n",
       "9115         77592.80       0  \n",
       "7502        136119.96       1  \n",
       "8385        125660.99       0  \n",
       "4771         12099.67       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downloading the data\n",
    "data=pd.read_csv('/datasets/Churn.csv')\n",
    "\n",
    "# Examining the size of Dataframe\n",
    "print('The dataframe size:',data.shape)\n",
    "\n",
    "# Examining the first 10 rows of dataframe\n",
    "print()\n",
    "print('Examining the first 10 rows of data in the dataframe:')\n",
    "display(data.head(10))\n",
    "\n",
    "# Checking 10 random rows to get an idea about the data\n",
    "print()\n",
    "print('Examining 10 random rows:')\n",
    "display(data.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender feature categories and unique values:\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "Geography feature categories and unique values:\n",
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: Geography, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examining the Gender feature\n",
    "print()\n",
    "print('Gender feature categories and unique values:')\n",
    "print(data['Gender'].value_counts())\n",
    "# Examining the Geography feature\n",
    "print()\n",
    "print('Geography feature categories and unique values:')\n",
    "print(data['Geography'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in any feature in the dataset\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenure statistics:\n",
      "------------------------------\n",
      "count    9091.000000\n",
      "mean        4.997690\n",
      "std         2.894723\n",
      "min         0.000000\n",
      "25%         2.000000\n",
      "50%         5.000000\n",
      "75%         7.000000\n",
      "max        10.000000\n",
      "Name: Tenure, dtype: float64\n",
      "------------------------------\n",
      "Total rows: 10000\n",
      "------------------------------\n",
      "Missing Tenure values: 909\n",
      "------------------------------\n",
      "Churn rate for missing Tenure:\n",
      "0    0.79868\n",
      "1    0.20132\n",
      "Name: Exited, dtype: float64\n",
      "\n",
      "Churn rate for non-missing Tenure:\n",
      "0    0.796062\n",
      "1    0.203938\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Examining the missing Tenure data\n",
    "print(\"Tenure statistics:\")\n",
    "print('-'*30)\n",
    "print(data['Tenure'].describe())\n",
    "print('-'*30)\n",
    "print(f\"Total rows: {len(data)}\")\n",
    "print('-'*30)\n",
    "print(f\"Missing Tenure values: {data['Tenure'].isnull().sum()}\")\n",
    "print('-'*30)\n",
    "\n",
    "# Check if missing Tenure correlates with target\n",
    "missing_tenure = data['Tenure'].isnull()\n",
    "print(\"Churn rate for missing Tenure:\")\n",
    "print(data[missing_tenure]['Exited'].value_counts(normalize=True))\n",
    "print(\"\\nChurn rate for non-missing Tenure:\")\n",
    "print(data[~missing_tenure]['Exited'].value_counts(normalize=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that no other feature has missing data and there is no way we can  predict if these values were missed in error or they were supposed to be near mean/median values.\n",
    "We also see that introducing mean value into this missing data has a potential to harm the model efficiency. \n",
    "We noticed in our analysis that the churn data is nearly similar, which means that dropping these rows won't have much impact on our data to be used for model predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RowNumber          0\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dropping the rows with missing values in Tenure column\n",
    "data=data.dropna(subset=['Tenure'])\n",
    "\n",
    "# Confirming that no null values exist\n",
    "print()\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examining the class imbalance for Target feature Exited:\n",
      "0    7237\n",
      "1    1854\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Investigating the class imbalance for Target feature 'Exited'\n",
    "print()\n",
    "print('Examining the class imbalance for Target feature Exited:')\n",
    "print(data['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dataset size: (9091,)\n",
      "Features dataset size: (9091, 10)\n",
      "Features overview:\n",
      "   CreditScore  Geography  Gender   Age  Tenure  Balance  NumOfProducts  \\\n",
      "0        226.0        0.0     0.0  24.0     2.0      0.0            0.0   \n",
      "1        215.0        2.0     0.0  23.0     1.0    679.0            0.0   \n",
      "2        109.0        0.0     0.0  24.0     8.0   5277.0            2.0   \n",
      "3        306.0        0.0     0.0  21.0     1.0      0.0            1.0   \n",
      "4        457.0        2.0     0.0  25.0     2.0   3374.0            0.0   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0        1.0             1.0           4609.0  \n",
      "1        0.0             1.0           5119.0  \n",
      "2        1.0             0.0           5182.0  \n",
      "3        0.0             0.0           4274.0  \n",
      "4        1.0             1.0           3559.0  \n",
      "\n",
      "Training target data size: (5454,)\n",
      "Validation target data size: (1818,)\n",
      "Test target data size: (1819,)\n",
      "\n",
      "Training features data size: (5454, 10)\n",
      "Validation features data size: (1818, 10)\n",
      "Test features test data size: (1819, 10)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# The data frame has all numeric columns other than 'Geography' and 'Gender' which needs to be encoded for processing\n",
    "\n",
    "# Creates instance of class OrdinalEncoder and tunes the encoder to data to recognize which features are categorical\n",
    "encoder=OrdinalEncoder()\n",
    "encoder.fit(data)\n",
    "# Transforms the data and add column names\n",
    "data_ordinal=pd.DataFrame(encoder.transform(data),columns=data.columns)\n",
    "\n",
    "\n",
    "# Preparing the data for modeling\n",
    "\n",
    "# Assigning features and target\n",
    "target=data_ordinal['Exited']\n",
    "# Dropping Rownumber,CustomerId and Surname wince these are irrelevant columns for model training\n",
    "features=data_ordinal.drop(['Exited','RowNumber','CustomerId','Surname'],axis=1)\n",
    "print('Target dataset size:', target.shape)\n",
    "print('Features dataset size:', features.shape)\n",
    "print('Features overview:')\n",
    "print(features.head(5))\n",
    "\n",
    "## CHANGED features_train to features_main\n",
    "## CHANGED target_train to target_main\n",
    "\n",
    "# Splitting the entire dataset into 60% : 20% : 20% ratio as Train:Validate:Test dataset\n",
    "# Splitting data into a main set and test set with test size 20% of the entire dataset\n",
    "features_main, features_test, target_main, target_test=train_test_split(features,target,test_size=0.20,random_state=12345)\n",
    "# Splitting data into a training set and validation set with test size 25% of the 'main' dataset (0.25 * 0.8 = 0.2)\n",
    "features_train, features_valid, target_train, target_valid=train_test_split(features_main, target_main, test_size=0.25,random_state=12345)\n",
    "\n",
    "# Testing if the Data was split correctly\n",
    "print()\n",
    "print('Training target data size:', target_train.shape)\n",
    "print('Validation target data size:', target_valid.shape)\n",
    "print('Test target data size:', target_test.shape)\n",
    "\n",
    "print()\n",
    "print('Training features data size:', features_train.shape)\n",
    "print('Validation features data size:', features_valid.shape)\n",
    "print('Test features test data size:', features_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2: \n",
    "Examining balance of classes and training the model without taking into account the imbalance while describing the findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline F1 score for RandomForestClassifier without class adjustment: 0.4962121212121212\n",
      "\n",
      "AUC-ROC Score: 0.8466370109440153\n",
      "\n",
      "Investigating the class imbalance for target feature : Exited\n",
      "0.0    7237\n",
      "1.0    1854\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Employing RandomForestClassifier with number of trees 50 and depth parameter 8\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "\n",
    "model=RandomForestClassifier(random_state=12345,n_estimators=50,max_depth=8)\n",
    "model.fit(features_train,target_train)\n",
    "predicted_valid=model.predict(features_valid)\n",
    "f1_score_baseline=f1_score(target_valid,predicted_valid)\n",
    "\n",
    "print('Baseline F1 score for RandomForestClassifier without class adjustment:', f1_score_baseline)\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc_score = roc_auc_score(target_valid,probabilities_one_valid)\n",
    "\n",
    "print()\n",
    "print('AUC-ROC Score:', auc_roc_score)\n",
    "print()\n",
    "print('Investigating the class imbalance for target feature : Exited')\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score: 0.49 ; This is below the project target:0.59 This tells us that the model struggles with precision and recall balance, especially for churned customers(minority). The imbalance is hurting the F1 score despite good pattern recognition.\n",
    "AUC-ROC Score: 0.84 ; This is good, considering above 0.8 is considered good This tells us that the model can distinguish between the classes well and understands the patterns\n",
    "Moreover, we see the Class Imbalance: 0.0: 7237 customers(79.6%) and 1.0: 1854 customer(20.4%) showing significant Class Imbalance about 80/20 split which explains the model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 3: Improving Quality of the Model by using approach to fix Class Imbalance and using Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Weight Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Logistic Regression with Class Weight Adjustment: 0.47813411078717194\n",
      "AUC-ROC Score for Logistic Regression with Class Weight Adjustment: 0.7597886465248611\n"
     ]
    }
   ],
   "source": [
    "# Applying Class weight adjustment on Logistic Regression to see if F1 score improves\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_logistic=LogisticRegression(random_state=12345, solver= 'liblinear', class_weight= 'balanced')\n",
    "model_logistic.fit(features_train,target_train)\n",
    "predicted_logistic=model_logistic.predict(features_valid)\n",
    "f1_score_logistic=f1_score(target_valid, predicted_logistic)\n",
    "\n",
    "print('F1 score for Logistic Regression with Class Weight Adjustment:', f1_score_logistic)\n",
    "\n",
    "probabilities_valid_lr_w = model_logistic.predict_proba(features_valid)\n",
    "probabilities_one_valid_lr_w = probabilities_valid_lr_w[:, 1]\n",
    "auc_roc_score_lr_w = roc_auc_score(target_valid,probabilities_one_valid_lr_w)\n",
    "\n",
    "print('AUC-ROC Score for Logistic Regression with Class Weight Adjustment:', auc_roc_score_lr_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for RandomForestClassifier with Class Weight Adjustment: 0.5954198473282444\n",
      "AUC-ROC Score RandomForestClassifier with Class Weight Adjustment: 0.8444862183684836\n"
     ]
    }
   ],
   "source": [
    "# Applying Class weight adjustment on RandomForestClassifier to see if F1 score improves\n",
    "\n",
    "\n",
    "model_rand_forest_weighted=RandomForestClassifier(random_state=12345, n_estimators=50, max_depth=8, class_weight= 'balanced')\n",
    "model_rand_forest_weighted.fit(features_train,target_train)\n",
    "predicted_rand_forest_weighted=model_rand_forest_weighted.predict(features_valid)\n",
    "f1_score_rand_forest_weighted=f1_score(target_valid, predicted_rand_forest_weighted)\n",
    "\n",
    "print('F1 score for RandomForestClassifier with Class Weight Adjustment:', f1_score_rand_forest_weighted)\n",
    "\n",
    "probabilities_valid_rfc_w = model_rand_forest_weighted.predict_proba(features_valid)\n",
    "probabilities_one_valid_rfc_w = probabilities_valid_rfc_w[:, 1]\n",
    "auc_roc_score_rfc_w = roc_auc_score(target_valid,probabilities_one_valid_rfc_w)\n",
    "\n",
    "print('AUC-ROC Score RandomForestClassifier with Class Weight Adjustment:', auc_roc_score_rfc_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we see that RandomForestClassifier performed much better than LogisticRegression algorithm, giving us F1 score  slightly higher than 0.59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Logistic Regression with Upsampling: 0.3990772779700116\n",
      "AUC-ROC Score for Logistic Regression with Upsampling: 0.7617663219377078\n"
     ]
    }
   ],
   "source": [
    "# Applying Upsampling on Logistic Regression to see if F1 score improves.\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Splitting training sample into negative and positive observations\n",
    "features_zeros=features_train[target_train==0]\n",
    "features_ones=features_train[target_train==1]\n",
    "target_zeros=target_train[target_train==0]\n",
    "target_ones=target_train[target_train==1]\n",
    "# Duplicating positive class observations and then combining them with negative class observations\n",
    "features_upsampled=pd.concat([features_zeros]+[features_ones]*10)\n",
    "target_upsampled=pd.concat([target_zeros]+[target_ones]*10)\n",
    "# Reseting indices as without these, we were getting an error in shuffling\n",
    "features_upsampled = features_upsampled.reset_index(drop=True)\n",
    "target_upsampled = target_upsampled.reset_index(drop=True)\n",
    "# Shuffling the data\n",
    "features_upsampled, target_upsampled= shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "#print(features_upsampled.shape, target_upsampled.shape)\n",
    "# Applying model algorithm\n",
    "model_logistic_upsampled=LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_logistic_upsampled.fit(features_upsampled,target_upsampled)\n",
    "predicted_logistic_upsampled=model_logistic_upsampled.predict(features_valid)\n",
    "f1_score_logistic_upsampled=f1_score(target_valid, predicted_logistic_upsampled)\n",
    "print('F1 score for Logistic Regression with Upsampling:', f1_score_logistic_upsampled)\n",
    "\n",
    "probabilities_valid_logistic_upsampled = model_logistic_upsampled.predict_proba(features_valid)\n",
    "probabilities_one_valid_logistic_upsampled = probabilities_valid_logistic_upsampled[:, 1]\n",
    "auc_roc_score_logistic_upsampled = roc_auc_score(target_valid,probabilities_one_valid_logistic_upsampled)\n",
    "print('AUC-ROC Score for Logistic Regression with Upsampling:', auc_roc_score_logistic_upsampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for RandomForestClassifier with Upsampling: 0.5086887835703002\n",
      "AUC-ROC Score for RandomForestClassifier with Upsampling: 0.8403257613391741\n"
     ]
    }
   ],
   "source": [
    "# Applying Upsampling on RandomForestClassifier to see if F1 score improves\n",
    "model_random_forest_upsampling=RandomForestClassifier(random_state=12345, n_estimators=50, max_depth=8)\n",
    "model_random_forest_upsampling.fit(features_upsampled,target_upsampled)\n",
    "predicted_random_forest_upsampling=model_random_forest_upsampling.predict(features_valid)\n",
    "f1_score_random_forest_upsampling=f1_score(target_valid, predicted_random_forest_upsampling)\n",
    "print('F1 score for RandomForestClassifier with Upsampling:', f1_score_random_forest_upsampling)\n",
    "\n",
    "probabilities_valid_random_forest_upsampling = model_random_forest_upsampling.predict_proba(features_valid)\n",
    "probabilities_one_valid_random_forest_upsampling = probabilities_valid_random_forest_upsampling[:, 1]\n",
    "auc_roc_score_random_forest_upsampling = roc_auc_score(target_valid,probabilities_one_valid_random_forest_upsampling)\n",
    "print('AUC-ROC Score for RandomForestClassifier with Upsampling:', auc_roc_score_random_forest_upsampling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current class 0 samples in training: 4335\n",
      "Current class 1 samples in training: 1119\n"
     ]
    }
   ],
   "source": [
    "# Analysing number of class 0 and class 1 samples to decide frac value while downsampling\n",
    "print(f\"Current class 0 samples in training: {len(features_zeros)}\")\n",
    "print(f\"Current class 1 samples in training: {len(features_ones)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Logistic Regression with Downsampling: 0.4807881773399015\n",
      "AUC-ROC Score for Logistic Regression with Downsampling: 0.761736214605067\n"
     ]
    }
   ],
   "source": [
    "# Applying Downsampling on Logistic Regression to see if F1 score improves.\n",
    "\n",
    "features_zeros_downsampled=features_zeros.sample(frac=0.26,random_state=12345)\n",
    "target_zeros_downsampled=target_zeros.sample(frac=0.26, random_state=12345)\n",
    "\n",
    "features_downsampled=pd.concat([features_zeros_downsampled]+[features_ones])\n",
    "target_downsampled=pd.concat([target_zeros_downsampled]+[target_ones])\n",
    "features_downsampled,target_downsampled=shuffle(features_downsampled,target_downsampled,random_state=12345)\n",
    "\n",
    "model_logistic_downsampled=LogisticRegression(solver='liblinear', random_state=12345)\n",
    "model_logistic_downsampled.fit(features_downsampled,target_downsampled)\n",
    "\n",
    "predicted_logistic_downsampled=model_logistic_downsampled.predict(features_valid)\n",
    "f1_score_logistic_downsampled=f1_score(target_valid, predicted_logistic_downsampled)\n",
    "print('F1 score for Logistic Regression with Downsampling:', f1_score_logistic_downsampled)\n",
    "\n",
    "probabilities_valid_logistic_downsampled = model_logistic_downsampled.predict_proba(features_valid)\n",
    "probabilities_one_valid_logistic_downsampled = probabilities_valid_logistic_downsampled[:, 1]\n",
    "auc_roc_score_logistic_downsampled = roc_auc_score(target_valid,probabilities_one_valid_logistic_downsampled)\n",
    "print('AUC-ROC Score for Logistic Regression with Downsampling:', auc_roc_score_logistic_downsampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for RandomForestClassifier with Downsampling: 0.56045197740113\n",
      "AUC-ROC Score for RandomForestClassifier with Downsampling: 0.8408695750349998\n"
     ]
    }
   ],
   "source": [
    "# Applying Downsampling on RandomForestClassifier to see if F1 score improves.\n",
    "model_random_forest_downsampling=RandomForestClassifier(random_state=12345, n_estimators=50, max_depth=8)\n",
    "model_random_forest_downsampling.fit(features_downsampled,target_downsampled)\n",
    "predicted_random_forest_downsampling=model_random_forest_downsampling.predict(features_valid)\n",
    "f1_score_random_forest_downsampling=f1_score(target_valid, predicted_random_forest_downsampling)\n",
    "print('F1 score for RandomForestClassifier with Downsampling:', f1_score_random_forest_downsampling)\n",
    "\n",
    "probabilities_valid_random_forest_downsampling = model_random_forest_downsampling.predict_proba(features_valid)\n",
    "probabilities_one_valid_random_forest_downsampling = probabilities_valid_random_forest_downsampling[:, 1]\n",
    "auc_roc_score_random_forest_downsampling = roc_auc_score(target_valid,probabilities_one_valid_random_forest_downsampling)\n",
    "print('AUC-ROC Score for RandomForestClassifier with Downsampling:', auc_roc_score_random_forest_downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold adjustment\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.30 | Precision = 0.410, Recall = 0.495, F1 = 0.449\n",
      "Threshold = 0.35 | Precision = 0.458, Recall = 0.388, F1 = 0.420\n",
      "Threshold = 0.40 | Precision = 0.546, Recall = 0.322, F1 = 0.405\n",
      "Threshold = 0.45 | Precision = 0.570, Recall = 0.235, F1 = 0.333\n",
      "Threshold = 0.50 | Precision = 0.627, Recall = 0.175, F1 = 0.274\n",
      "Threshold = 0.55 | Precision = 0.651, Recall = 0.112, F1 = 0.191\n",
      "Threshold = 0.60 | Precision = 0.732, Recall = 0.082, F1 = 0.147\n",
      "Threshold = 0.65 | Precision = 0.714, Recall = 0.041, F1 = 0.078\n",
      "Threshold = 0.70 | Precision = 0.727, Recall = 0.022, F1 = 0.042\n",
      "Threshold = 0.75 | Precision = 1.000, Recall = 0.016, F1 = 0.032\n"
     ]
    }
   ],
   "source": [
    "# Applying Threshold adjustment on Logistic Regression to see if F1 score improves.\n",
    "\n",
    "model_logistic_threshold=LogisticRegression(solver='liblinear', random_state=12345)\n",
    "model_logistic_threshold.fit(features_train,target_train)\n",
    "\n",
    "probabilities_valid_logistic_threshold=model_logistic_threshold.predict_proba(features_valid)\n",
    "probabilities_valid_logistic_threshold=probabilities_valid_logistic_threshold[:,1]\n",
    "\n",
    "for threshold in np.arange(0.3, 0.8, 0.05):\n",
    "    predicted_valid_logistic_threshold=probabilities_valid_logistic_threshold>threshold\n",
    "    precision_logistic_threshold=precision_score(target_valid, predicted_valid_logistic_threshold)\n",
    "    recall_logistic_threshold=recall_score(target_valid, predicted_valid_logistic_threshold)\n",
    "    f1_logistic_threshold=f1_score(target_valid, predicted_valid_logistic_threshold)\n",
    "    print('Threshold = {:.2f} | Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3f}'.format(\n",
    "        threshold, precision_logistic_threshold, recall_logistic_threshold, f1_logistic_threshold))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that F1 score is highest when Threshold is 0.30 but, is below the reqiured 0.59 F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.30 | Precision = 0.356, Recall = 0.880, F1 = 0.507, AUC-ROC = 0.844\n",
      "Threshold = 0.35 | Precision = 0.405, Recall = 0.833, F1 = 0.545, AUC-ROC = 0.844\n",
      "Threshold = 0.40 | Precision = 0.450, Recall = 0.751, F1 = 0.563, AUC-ROC = 0.844\n",
      "Threshold = 0.45 | Precision = 0.502, Recall = 0.702, F1 = 0.585, AUC-ROC = 0.844\n",
      "Threshold = 0.50 | Precision = 0.557, Recall = 0.639, F1 = 0.595, AUC-ROC = 0.844\n",
      "Threshold = 0.55 | Precision = 0.604, Recall = 0.571, F1 = 0.587, AUC-ROC = 0.844\n",
      "Threshold = 0.60 | Precision = 0.647, Recall = 0.511, F1 = 0.571, AUC-ROC = 0.844\n",
      "Threshold = 0.65 | Precision = 0.708, Recall = 0.451, F1 = 0.551, AUC-ROC = 0.844\n",
      "Threshold = 0.70 | Precision = 0.756, Recall = 0.399, F1 = 0.522, AUC-ROC = 0.844\n",
      "Threshold = 0.75 | Precision = 0.827, Recall = 0.339, F1 = 0.481, AUC-ROC = 0.844\n"
     ]
    }
   ],
   "source": [
    "# Applying Threshold adjustment on RandomForestClassifier with ClassWeightAdjustment to see if F1 score improves.\n",
    "\n",
    "probabilities_valid_rf_weighted_threshold=model_rand_forest_weighted.predict_proba(features_valid)\n",
    "probabilities_valid_rf_weighted_threshold=probabilities_valid_rf_weighted_threshold[:,1]\n",
    "\n",
    "for threshold in np.arange(0.3, 0.8, 0.05):\n",
    "    predicted_valid_rf_weighted_threshold=probabilities_valid_rf_weighted_threshold>threshold\n",
    "    precision_rf_weighted_threshold=precision_score(target_valid, predicted_valid_rf_weighted_threshold)\n",
    "    recall_rf_weighted_threshold=recall_score(target_valid, predicted_valid_rf_weighted_threshold)\n",
    "    f1_rf_weighted_threshold=f1_score(target_valid, predicted_valid_rf_weighted_threshold)\n",
    "    auc_roc_scorerf_weighted_threshold = roc_auc_score(target_valid,probabilities_valid_rf_weighted_threshold)\n",
    "\n",
    "    print('Threshold = {:.2f} | Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3f}, AUC-ROC = {:.3f}'.format(\n",
    "        threshold, precision_rf_weighted_threshold, recall_rf_weighted_threshold, f1_rf_weighted_threshold, auc_roc_scorerf_weighted_threshold))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that F1 score(0.595) is highest when Threshold is 0.50 and exceeds the reqiured 0.59 F1 score well. Infact, combining RandomForestClassifier with class weight adjustment with Threshold adjustment gave us one of our best F1 score yet. This means that our model correctly identifies about 55.7% of predicted churners(precision) and catches about 63.9% of actual churners(recall). The AUC-ROC score of ~0.84 is also excellent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL SUMMARY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between all approaches tested:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "      <th>Meets_Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline RandomForest</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.846</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline Logistic Regression (implied)</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest + Class Weight</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.844</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression + Class Weight</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.759</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest + Upsampling</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.840</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression + Upsampling</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.761</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest + Downsampling</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.840</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression + Downsampling</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.761</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression + Threshold (0.30)</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest + Class Weight + Threshold (0.50)</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.844</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Approach                   Model  \\\n",
       "0                           Baseline RandomForest  RandomForestClassifier   \n",
       "1          Baseline Logistic Regression (implied)      LogisticRegression   \n",
       "2                     RandomForest + Class Weight  RandomForestClassifier   \n",
       "3              Logistic Regression + Class Weight      LogisticRegression   \n",
       "4                       RandomForest + Upsampling  RandomForestClassifier   \n",
       "5                Logistic Regression + Upsampling      LogisticRegression   \n",
       "6                     RandomForest + Downsampling  RandomForestClassifier   \n",
       "7              Logistic Regression + Downsampling      LogisticRegression   \n",
       "8          Logistic Regression + Threshold (0.30)      LogisticRegression   \n",
       "9  RandomForest + Class Weight + Threshold (0.50)  RandomForestClassifier   \n",
       "\n",
       "   F1_Score  AUC_ROC Meets_Target  \n",
       "0     0.496    0.846           No  \n",
       "1       NaN      NaN          N/A  \n",
       "2     0.595    0.844          Yes  \n",
       "3     0.478    0.759           No  \n",
       "4     0.508    0.840           No  \n",
       "5     0.399    0.761           No  \n",
       "6     0.560    0.840          Yes  \n",
       "7     0.480    0.761           No  \n",
       "8     0.449      NaN           No  \n",
       "9     0.595    0.844          Yes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {\n",
    "    'Approach': [\n",
    "        'Baseline RandomForest',\n",
    "        'Baseline Logistic Regression (implied)',\n",
    "        'RandomForest + Class Weight',\n",
    "        'Logistic Regression + Class Weight', \n",
    "        'RandomForest + Upsampling',\n",
    "        'Logistic Regression + Upsampling',\n",
    "        'RandomForest + Downsampling',\n",
    "        'Logistic Regression + Downsampling',\n",
    "        'Logistic Regression + Threshold (0.30)',\n",
    "        'RandomForest + Class Weight + Threshold (0.50)'\n",
    "    ],\n",
    "    'Model': [\n",
    "        'RandomForestClassifier',\n",
    "        'LogisticRegression',\n",
    "        'RandomForestClassifier',\n",
    "        'LogisticRegression',\n",
    "        'RandomForestClassifier', \n",
    "        'LogisticRegression',\n",
    "        'RandomForestClassifier',\n",
    "        'LogisticRegression',\n",
    "        'LogisticRegression',\n",
    "        'RandomForestClassifier'\n",
    "    ],\n",
    "    'F1_Score': [\n",
    "        0.496,  # baseline\n",
    "        None,   # not directly tested\n",
    "        0.595,  # class weight\n",
    "        0.478,  # class weight\n",
    "        0.508,  # upsampling\n",
    "        0.399,  # upsampling\n",
    "        0.560,  # downsampling\n",
    "        0.480,  # downsampling\n",
    "        0.449,  # threshold 0.30\n",
    "        0.595   # class weight + threshold 0.50\n",
    "    ],\n",
    "    'AUC_ROC': [\n",
    "        0.846,  # baseline\n",
    "        None,   # not directly tested\n",
    "        0.844,  # class weight\n",
    "        0.759,  # class weight\n",
    "        0.840,  # upsampling\n",
    "        0.761,  # upsampling\n",
    "        0.840,  # downsampling\n",
    "        0.761,  # downsampling\n",
    "        None,   # threshold (would be same as baseline LR)\n",
    "        0.844   # class weight + threshold 0.50\n",
    "    ],\n",
    "    'Meets_Target': [\n",
    "        'No',   # 0.496 < 0.59\n",
    "        'N/A',\n",
    "        'Yes',  # 0.595 > 0.59 (BEST)\n",
    "        'No',   # 0.478 < 0.59\n",
    "        'No',   # 0.508 < 0.59\n",
    "        'No',   # 0.399 < 0.59\n",
    "        'Yes',  # 0.560 > 0.59\n",
    "        'No',   # 0.480 < 0.59\n",
    "        'No',   # 0.449 < 0.59\n",
    "        'Yes'   # 0.595 > 0.59 (BEST)\n",
    "    ]\n",
    "}\n",
    "# Creating Dataframe\n",
    "summary=pd.DataFrame(results)\n",
    "print('Comparison between all approaches tested:')\n",
    "print('-'*100)\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST PERFORMING APPROACH:\n",
      "Method: RandomForest + Class Weight & RandomForest + Class Weight+Threshold Adjustment\n",
      "F1 Score: 0.595\n",
      "AUC-ROC: 0.844\n"
     ]
    }
   ],
   "source": [
    "# best_f1_idx = summary_df['F1_Score'].idxmax()\n",
    "best_f1_idx = summary['F1_Score'].idxmax()\n",
    "print(f\"\\nBEST PERFORMING APPROACH:\")\n",
    "print(f\"Method: {summary.loc[best_f1_idx, 'Approach']} & RandomForest + Class Weight+Threshold Adjustment\")\n",
    "print(f\"F1 Score: {summary.loc[best_f1_idx, 'F1_Score']}\")\n",
    "print(f\"AUC-ROC: {summary.loc[best_f1_idx, 'AUC_ROC']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL RESULT FOR BEST MODEL (RandomForest + Class Weight)\n",
      "============================================================\n",
      "\n",
      "**VALIDATION SET** \n",
      "F1 = 0.595, AUC-ROC = 0.844\n",
      "\n",
      "**TEST SET** \n",
      "F1 = 0.596, AUC-ROC = 0.851\n"
     ]
    }
   ],
   "source": [
    "# Applying the best model(RandomForest + Class Weight) to the training, validation and test set\n",
    "\n",
    "model_rand_forest_weighted_final=RandomForestClassifier(random_state=12345, n_estimators=50, max_depth=8, class_weight= 'balanced')\n",
    "model_rand_forest_weighted_final.fit(features_train,target_train)\n",
    "predicted_rand_forest_weighted_final=model_rand_forest_weighted_final.predict(features_valid)\n",
    "f1_score_rand_forest_weighted_final=f1_score(target_valid, predicted_rand_forest_weighted_final)\n",
    "\n",
    "probabilities_valid_rfc_w_final = model_rand_forest_weighted_final.predict_proba(features_valid)\n",
    "probabilities_one_valid_rfc_w_final = probabilities_valid_rfc_w_final[:, 1]\n",
    "auc_roc_score_rfc_w_final = roc_auc_score(target_valid,probabilities_one_valid_rfc_w_final)\n",
    "\n",
    "print('='*60)\n",
    "print('FINAL RESULT FOR BEST MODEL (RandomForest + Class Weight)')\n",
    "print('='*60)\n",
    "\n",
    "print('\\n**VALIDATION SET** \\nF1 = {:.3f}, AUC-ROC = {:.3f}'.format(f1_score_rand_forest_weighted_final, auc_roc_score_rfc_w_final))\n",
    "\n",
    "predicted_final=model_rand_forest_weighted_final.predict(features_test)\n",
    "f1_final=f1_score(target_test,predicted_final)\n",
    "probabilities_valid_final=model_rand_forest_weighted_final.predict_proba(features_test)\n",
    "probabilities_valid_final=probabilities_valid_final[:, 1]\n",
    "auc_roc_score_final=roc_auc_score(target_test, probabilities_valid_final)\n",
    "\n",
    "print('\\n**TEST SET** \\nF1 = {:.3f}, AUC-ROC = {:.3f}'.format(f1_final, auc_roc_score_final))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started the project with Data Preparation by:\n",
    "\t1. Importing the required library for Data Preparation phase\n",
    "\t2. Downloading the data and examining it to understand it's basic structure\n",
    "\t3. Examining the data to see the feature categories, finding features with missing values and features with categorical values\n",
    "\t4. Only one feature was found with missing values 'Tenure'. It was examined for it's statistical values, any dependencies, churn rate relating to this feature. It was determined  during our analysis that we drop the rows from out Dataframe having missing values in this feature to build the most efficient model.\n",
    "\t5. Examined class imbalance for Target feature 'Exited'.\n",
    "\n",
    "I then moved on to the Pre Processing phase which included the following steps:\n",
    "\t1. Importing the required library for Data Pre Processing phase\n",
    "\t2. Identifying the right encoding technique, and transforming the data\n",
    "\t3. Dropping unnecessary columns like Surname which are not relevant for model prediction.\n",
    "\t4. Assigning 'features' and 'target' columns and evaluating their sizes\n",
    "\t5. Splitting the data into sets with standard validation size 20%, test size 20% and testing the split execution.\n",
    "\n",
    "I then moved onto balancing the classes and training the model without taking into account the imbalance:\n",
    "\t1. I used RandomForestClassifier model. \n",
    "\t2. F1 score and AUC-ROC scores were evaluated for establishing a baseline.\n",
    "\t3. A brief summary was given at the end.\n",
    "\n",
    "I then addressed Class Imbalance and tested it:\n",
    "\t1. Class weight adjustment was applied and F1 score, AUC-ROC score was calculated for LogisticRegression and RandomForestClassifier. Findings were summarized.\n",
    "\t2. Upsampling was applied and F1 score, AUC-ROC score was calculated for LogisticRegression and RandomForestClassifier. Findings were summarized.\n",
    "\t3. Downsampling was applied and F1 score, AUC-ROC score was calculated for LogisticRegression and RandomForestClassifier. Findings were summarized.\n",
    "\t4. Threshold adjustment was applied to find the best threshold value. F1 score, AUC-ROC score was calculated for LogisticRegression.\n",
    "\t5.  Threshold adjustment was applied to the existing downsampled model of RandomForestClassifier, since that had given us the best scores so far. Findings were summarized.\n",
    "\n",
    "Finally, a table showing all approaches side by side were displayed. The best performing approach was listed with all statistics. The Best Model was applied to the training set and Test set finally where we noticed out Test set performing slightl better than even our training set.\n",
    "\t\n",
    "\t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
